{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4A Group 11 Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "E41m8YffEa8d",
        "0V2vSggNY4dS",
        "f9pEjuNrLk-g",
        "nz_X7SsCFU-G",
        "e-_5OPRqF3uT",
        "ktlIsGnkGjAN",
        "5Zai2JmlVJXy"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CVwot-HKc8T"
      },
      "source": [
        "#**Fake News Classifier (NLP)**\n",
        "\n",
        "110740 Mwandware Dalton Zai \n",
        "\n",
        "110855 Wesley Joel Odhiambo\n",
        "\n",
        "Dataset:\n",
        "https://www.kaggle.com/c/fake-news"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N76OfBfYTJhT"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "# import spacy\n",
        "\n",
        "import re as re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkudnRFDEoDZ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E41m8YffEa8d"
      },
      "source": [
        "#**Fetch Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmMqaMGIsWr6"
      },
      "source": [
        "train_data=pd.read_csv('/content/drive/MyDrive/Datasets/fake_news.csv')\n",
        "train_data = pd.DataFrame(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ2Y969tJrYR"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqf_dZTSXuZm"
      },
      "source": [
        "train_data.drop('id',inplace=True,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mBu6ZAbYCKc"
      },
      "source": [
        "train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_4s_JflW9WV"
      },
      "source": [
        "len(list(train_data.columns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V2vSggNY4dS"
      },
      "source": [
        "#**Check for Null values in Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_acWtg6QVrc"
      },
      "source": [
        "train_data.isnull().sum()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lFQfGCZadw_"
      },
      "source": [
        "features_missing_values=list(train_data.columns[train_data.isna().any()])\n",
        "len(features_missing_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9pEjuNrLk-g"
      },
      "source": [
        "#**Drop missing Values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB9g8Py2Lkus"
      },
      "source": [
        "new_train_data=train_data.dropna(axis=0,inplace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXkfDw-MOOoG"
      },
      "source": [
        "new_train_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIkRXqBJMcTb"
      },
      "source": [
        "new_train_data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7ahN1HfTBAT"
      },
      "source": [
        "train_final=new_train_data.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhATiNPCUd5g"
      },
      "source": [
        "new_train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFi84BuQ6r57"
      },
      "source": [
        "new_train_data.reset_index(inplace=True)\n",
        "new_train_data.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSEeEYJo3wPo"
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "corpus = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTTnEaLSVFZO"
      },
      "source": [
        "len(new_train_data[\"text\"].values), type(new_train_data['text'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz_X7SsCFU-G"
      },
      "source": [
        "#**Tokenizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGNf9E3aUsHx"
      },
      "source": [
        "UNIQUE_WORDS = 1500\n",
        "corpus  = list(new_train_data[\"text\"].values)\n",
        "tokenizer = Tokenizer(num_words=1500, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "word_indices = tokenizer.word_index\n",
        "word_count = tokenizer.document_count\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQE_jXCpZEHP"
      },
      "source": [
        "encoded_corpus = tokenizer.texts_to_sequences(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsT--vpBcPIy"
      },
      "source": [
        "encoded_corpus = pad_sequences(encoded_corpus, maxlen=50, padding='post')\n",
        "ds_y = new_train_data[\"label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3bx_jt-an-V"
      },
      "source": [
        "# Coversion to Tensor\n",
        "ds_corpus = tf.data.Dataset.from_tensor_slices((encoded_corpus, ds_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbPVPvXyboT8"
      },
      "source": [
        "for encoded_seq, label in ds_corpus.take(5):\n",
        "  print(f'Sequence shape: {encoded_seq.shape}, Label is: {label}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-_5OPRqF3uT"
      },
      "source": [
        "#**Split Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TovIXG9H77bR"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "dataset_size = ds_corpus.cardinality().numpy()\n",
        "\n",
        "train_size = dataset_size * 0.7\n",
        "val_size = dataset_size * 0.2\n",
        "test_size = dataset_size * 0.1\n",
        "\n",
        "ds_train = ds_corpus.take(train_size).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "ds_val = ds_corpus.skip(train_size).take(val_size).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "ds_test = ds_corpus.skip(train_size + val_size).take(test_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktlIsGnkGjAN"
      },
      "source": [
        "#**Build Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spSOoquTMe-c"
      },
      "source": [
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.callbacks import *\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h48Ye6sNM3vh"
      },
      "source": [
        "EMBEDDING_DIM = 512\n",
        "model = keras.models.Sequential([\n",
        "      keras.layers.Embedding(UNIQUE_WORDS, 512, input_length=50),\n",
        "      keras.layers.GRU(100, return_sequences=True, dropout=0.2, recurrent_dropout=0.3),\n",
        "      keras.layers.GRU(100, return_sequences=False, dropout=0.2, recurrent_dropout=0.3),\n",
        "      keras.layers.Dense(1,  activation=\"sigmoid\")\n",
        "      ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTYHRNUcGxhf"
      },
      "source": [
        "**Compile and Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViziwLuE64Ya"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "es=EarlyStopping(monitor='loss', verbose=1, patience=3)\n",
        "mc=ModelCheckpoint('best_model',save_best_only=True,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv16F8LyCYbZ"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLKgRGyyHCRv"
      },
      "source": [
        "#**Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRHrUBqWDH_K"
      },
      "source": [
        "history = model.fit(ds_train, validation_data=ds_val, epochs=100, callbacks=[es,mc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Zai2JmlVJXy"
      },
      "source": [
        "# **Model performance Graph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QssbNVPfLhZi"
      },
      "source": [
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phmtQD3YwVX0"
      },
      "source": [
        "best_model = keras.models.load_model('best_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDLKQY5NwoXa"
      },
      "source": [
        "len(model.predict(ds_test.take(1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yehuO6qyU5ZJ"
      },
      "source": [
        "#**Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRzja8qFYq0Z"
      },
      "source": [
        "pip install -q -U keras-tuner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZAssIpvYck1"
      },
      "source": [
        "import keras_tuner as kt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kow4yu0VHf5T"
      },
      "source": [
        "**Model Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBPNxWqqU26N"
      },
      "source": [
        "def model_builder(hp):\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "\n",
        "  model = keras.models.Sequential([\n",
        "      keras.layers.Embedding(UNIQUE_WORDS, 512, input_length=50),\n",
        "      keras.layers.GRU(units=hp_units, return_sequences=True, dropout=0.2, recurrent_dropout=0.3),\n",
        "      keras.layers.GRU(units=hp_units, return_sequences=False, dropout=0.2, recurrent_dropout=0.3),\n",
        "      keras.layers.Dense(1,  activation=\"sigmoid\")\n",
        "      ])\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=Adam(learning_rate=hp_learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjMqwZZiHnd3"
      },
      "source": [
        "**Tuner Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN2HsCy0YE4h"
      },
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qDDbnfdY415"
      },
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buChYrn3Htgm"
      },
      "source": [
        "**Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hKrYKVMZA4k"
      },
      "source": [
        "tuner.search(encoded_corpus, ds_y, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqahPVEAbojQ"
      },
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(encoded_corpus, ds_y, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9uysEmxbpoA"
      },
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(encoded_corpus, ds_y, epochs=best_epoch, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDsh_YLvcZtY"
      },
      "source": [
        "eval_result = hypermodel.evaluate(encoded_corpus, ds_y)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDEXxGeUNN0C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JG_AtXkNOk3"
      },
      "source": [
        "#**Tuned Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgnfF9KkNSgN"
      },
      "source": [
        "EMBEDDING_DIM = 512\n",
        "model = keras.models.Sequential([\n",
        "      keras.layers.Embedding(UNIQUE_WORDS, 512, input_length=50),\n",
        "      keras.layers.GRU(384, return_sequences=True, dropout=0.2, recurrent_dropout=0.3),\n",
        "      keras.layers.GRU(384, return_sequences=False, dropout=0.2, recurrent_dropout=0.3),\n",
        "      keras.layers.Dense(1,  activation=\"sigmoid\")\n",
        "      ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5rFeEgjNSgO"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "es=EarlyStopping(monitor='loss', verbose=1, patience=3)\n",
        "mc=ModelCheckpoint('best_model',save_best_only=True,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsytqV_9NSgO"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdprkhSUNSgO"
      },
      "source": [
        "history = model.fit(ds_train, validation_data=ds_val, epochs=100, callbacks=[es,mc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70GDN-BGNbwf"
      },
      "source": [
        "#**Model performance Graph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXU4mUJmNZBy"
      },
      "source": [
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}